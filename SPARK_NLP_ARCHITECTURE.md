# Spark NLP Pipeline Architecture

## ğŸ—ï¸ Pipeline Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         SPARK NLP PIPELINE                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Input DataFrame
     â”‚
     â”‚ Column: "text" (raw tweet text)
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 1: DocumentAssembler                                             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  â€¢ Input:  "text" column                                                â”‚
â”‚  â€¢ Output: "document" column (Spark NLP document format)                â”‚
â”‚  â€¢ Action: Converts raw text to structured document                     â”‚
â”‚  â€¢ Cleanup: Removes extra whitespace (shrink mode)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â”‚ Column: "document" (structured format)
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 2: Tokenizer                                                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  â€¢ Input:  "document" column                                            â”‚
â”‚  â€¢ Output: "token" column (array of tokens)                             â”‚
â”‚  â€¢ Action: Splits text into individual words/tokens                     â”‚
â”‚  â€¢ Example: "I love this!" â†’ ["I", "love", "this", "!"]                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â”‚ Columns: "document" + "token"
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 3: SentimentDL Model                                             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  â€¢ Model:  sentimentdl_use_twitter (pre-trained)                        â”‚
â”‚  â€¢ Input:  "document" + "token" columns                                 â”‚
â”‚  â€¢ Output: "sentiment_result" column (annotations)                      â”‚
â”‚  â€¢ Action: Deep learning sentiment classification                       â”‚
â”‚  â€¢ Classes: positive, negative, neutral                                 â”‚
â”‚  â€¢ Threshold: 0.6 (confidence level)                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â”‚ Column: "sentiment_result" (annotations)
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 4: Finisher                                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  â€¢ Input:  "sentiment_result" column                                    â”‚
â”‚  â€¢ Output: "sentiment_output" column (readable string)                  â”‚
â”‚  â€¢ Action: Converts annotations to simple string format                 â”‚
â”‚  â€¢ Example: [Annotation(...)] â†’ "positive"                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â”‚ Column: "sentiment_output" (string)
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  POST-PROCESSING: Extract Sentiment                                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  â€¢ Input:  "sentiment_output" column                                    â”‚
â”‚  â€¢ Output: "sentiment" column (standardized)                            â”‚
â”‚  â€¢ Action: Maps output to standard labels                               â”‚
â”‚  â€¢ Mapping: "positive" â†’ "positive"                                     â”‚
â”‚            "negative" â†’ "negative"                                      â”‚
â”‚            other â†’ "neutral"                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â”‚ Final Column: "sentiment"
     â”‚
     â–¼
Output DataFrame
(with sentiment analysis results)
```

## ğŸ”„ Function Call Flow

```
main()
  â”‚
  â”œâ”€> SparkProcessor.__init__()
  â”‚     â””â”€> Creates Spark session
  â”‚
  â””â”€> process_batch()
        â”‚
        â”œâ”€> data_loader.load_data()
        â”‚     â””â”€> Returns DataFrame with "text" column
        â”‚
        â”œâ”€> process_sentiment(df)
        â”‚     â”‚
        â”‚     â”œâ”€> setup_spark_nlp()
        â”‚     â”‚     â”‚
        â”‚     â”‚     â”œâ”€> Import Spark NLP components
        â”‚     â”‚     â”‚     â”œâ”€> DocumentAssembler
        â”‚     â”‚     â”‚     â”œâ”€> Tokenizer
        â”‚     â”‚     â”‚     â”œâ”€> SentimentDLModel
        â”‚     â”‚     â”‚     â””â”€> Finisher
        â”‚     â”‚     â”‚
        â”‚     â”‚     â”œâ”€> Configure each component
        â”‚     â”‚     â”‚
        â”‚     â”‚     â”œâ”€> Create Pipeline with all stages
        â”‚     â”‚     â”‚
        â”‚     â”‚     â””â”€> Return pipeline (or None if error)
        â”‚     â”‚
        â”‚     â”œâ”€> If pipeline exists:
        â”‚     â”‚     â”œâ”€> pipeline.fit(df)
        â”‚     â”‚     â”œâ”€> pipeline_model.transform(df)
        â”‚     â”‚     â”œâ”€> Extract sentiment from output
        â”‚     â”‚     â””â”€> Return df_with_sentiment
        â”‚     â”‚
        â”‚     â””â”€> Else (fallback):
        â”‚           â”œâ”€> Use original_sentiment column
        â”‚           â””â”€> Return df_with_sentiment
        â”‚
        â””â”€> build_hashtag_cooccurrence()
              â””â”€> Uses sentiment column for analysis
```

## ğŸ“Š Data Flow Example

### Input Tweet:
```
"I love this product! It's amazing! #happy #excited"
```

### Stage-by-Stage Transformation:

**1. DocumentAssembler Output:**
```
document: [
  {
    annotatorType: "document",
    begin: 0,
    end: 52,
    result: "I love this product! It's amazing! #happy #excited",
    metadata: {...}
  }
]
```

**2. Tokenizer Output:**
```
token: [
  {annotatorType: "token", begin: 0, end: 0, result: "I"},
  {annotatorType: "token", begin: 2, end: 5, result: "love"},
  {annotatorType: "token", begin: 7, end: 10, result: "this"},
  {annotatorType: "token", begin: 12, end: 18, result: "product"},
  ...
]
```

**3. SentimentDL Model Output:**
```
sentiment_result: [
  {
    annotatorType: "sentiment",
    begin: 0,
    end: 52,
    result: "positive",
    metadata: {
      "confidence": "0.9876"
    }
  }
]
```

**4. Finisher Output:**
```
sentiment_output: "positive"
```

**5. Final Output:**
```
sentiment: "positive"
```

## ğŸ”€ Error Handling Flow

```
setup_spark_nlp()
  â”‚
  â”œâ”€> Try:
  â”‚     â”œâ”€> Import Spark NLP
  â”‚     â”œâ”€> Create pipeline
  â”‚     â””â”€> Return pipeline âœ…
  â”‚
  â””â”€> Catch:
        â”œâ”€> ImportError (Spark NLP not installed)
        â”‚     â””â”€> Log warning â†’ Return None
        â”‚
        â””â”€> Exception (Other errors)
              â””â”€> Log error â†’ Return None

process_sentiment(df)
  â”‚
  â”œâ”€> pipeline = setup_spark_nlp()
  â”‚
  â”œâ”€> If pipeline is not None:
  â”‚     â”‚
  â”‚     â”œâ”€> Try:
  â”‚     â”‚     â”œâ”€> Fit pipeline
  â”‚     â”‚     â”œâ”€> Transform data
  â”‚     â”‚     â””â”€> Return results âœ…
  â”‚     â”‚
  â”‚     â””â”€> Catch Exception:
  â”‚           â””â”€> Log error â†’ Use fallback
  â”‚
  â””â”€> Fallback Mode:
        â”œâ”€> Use original_sentiment column
        â””â”€> Return results âœ…
```

## ğŸ¯ Component Responsibilities

### DocumentAssembler
- **Purpose:** Entry point for Spark NLP
- **Input:** Raw text string
- **Output:** Structured document annotation
- **Key Feature:** Handles text cleanup and normalization

### Tokenizer
- **Purpose:** Text segmentation
- **Input:** Document annotation
- **Output:** Array of token annotations
- **Key Feature:** Preserves position information for each token

### SentimentDL Model
- **Purpose:** Sentiment classification
- **Input:** Document + tokens
- **Output:** Sentiment prediction with confidence
- **Key Feature:** Deep learning model trained on Twitter data

### Finisher
- **Purpose:** Format conversion
- **Input:** Spark NLP annotations
- **Output:** Simple string values
- **Key Feature:** Makes results easy to use in downstream processing

## ğŸ”§ Configuration Points

### 1. DocumentAssembler
```python
.setInputCol("text")           # Change input column name
.setOutputCol("document")      # Change output column name
.setCleanupMode("shrink")      # Options: shrink, disabled, each
```

### 2. Tokenizer
```python
.setInputCols(["document"])    # Input columns
.setOutputCol("token")         # Output column name
```

### 3. SentimentDL Model
```python
.pretrained("sentimentdl_use_twitter", "en")  # Model name and language
.setInputCols(["document", "token"])          # Required inputs
.setOutputCol("sentiment_result")             # Output column
.setThreshold(0.6)                            # Confidence threshold (0.0-1.0)
```

### 4. Finisher
```python
.setInputCols(["sentiment_result"])  # Input columns
.setOutputCols(["sentiment_output"]) # Output column names
.setOutputAsArray(False)             # Single value vs array
.setCleanAnnotations(False)          # Include metadata
```

## ğŸ“ˆ Performance Characteristics

### Pipeline Creation (First Time)
```
setup_spark_nlp()
  â”œâ”€> Import libraries: ~1 second
  â”œâ”€> Download model: ~2-5 minutes (400MB)
  â”œâ”€> Load model: ~10-30 seconds
  â””â”€> Create pipeline: ~1 second
  
Total: ~3-6 minutes (first run only)
```

### Pipeline Creation (Subsequent)
```
setup_spark_nlp()
  â”œâ”€> Import libraries: ~1 second
  â”œâ”€> Load cached model: ~5-10 seconds
  â””â”€> Create pipeline: ~1 second
  
Total: ~7-12 seconds
```

### Sentiment Processing
```
process_sentiment(df)
  â”œâ”€> Setup pipeline: ~7-12 seconds (cached)
  â”œâ”€> Fit pipeline: ~1-2 seconds
  â”œâ”€> Transform data: ~0.5-1 second per 1000 tweets
  â””â”€> Extract results: ~0.1 second
  
Total: ~10-15 seconds + (0.5-1 sec per 1000 tweets)
```

## ğŸ¨ Visual Summary

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Raw Text    â”‚  "I love this product!"
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Document    â”‚  [Annotation(document, 0, 21, ...)]
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Tokens      â”‚  [Annotation(token, "I"), ...]
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Sentiment   â”‚  [Annotation(sentiment, "positive", confidence=0.98)]
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Output      â”‚  "positive"
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ” Debugging Tips

### Check Pipeline Stages
```python
pipeline = setup_spark_nlp()
if pipeline:
    stages = pipeline.getStages()
    print(f"Pipeline has {len(stages)} stages:")
    for stage in stages:
        print(f"  - {stage.__class__.__name__}")
```

### Inspect Intermediate Results
```python
# After transform
df_transformed.select("text", "document", "token", "sentiment_result").show(1, truncate=False)
```

### Monitor Performance
```python
import time
start = time.time()
df_result = process_sentiment(df)
print(f"Processing took {time.time() - start:.2f} seconds")
```

---

This architecture ensures robust, scalable, and maintainable sentiment analysis for your tweet analytics pipeline!

